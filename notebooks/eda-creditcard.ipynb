{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd1c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessart dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d721fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df_cc = pd.read_csv('../data/raw/creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c22975",
   "metadata": {},
   "source": [
    "## Checking the data out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5164f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc.head() # check the top 5 data in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc.info() # check the basic information about the dataset such as datatypes and non-null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4000492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc.describe() # Statistical summery of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded4c97b",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a882993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling missing values\n",
    "df_cc.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489dd28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicate values\n",
    "df_cc.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d16f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cc.drop_duplicates(inplace=True)\n",
    "df_cc.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eeb16f",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the target variable 'Class'\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Class', data=df_cc)\n",
    "plt.title('Distribution of Fraudulent vs Non-Fraudulent Transactions')\n",
    "plt.xlabel('Is Fraud')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a82cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 'Amount' variable\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(df_cc['Amount'], bins=100, kde=True)\n",
    "plt.title('Distribution of Transaction Amounts')\n",
    "plt.xlabel('Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim(0, 5000) # Limiting for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4951a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 'Time' variable\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.histplot(df_cc['Time'], bins=100, kde=True)\n",
    "plt.title('Distribution of Transaction Time')\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc302f0b",
   "metadata": {},
   "source": [
    "### Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7bd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relationship between 'Amount' and 'Class'\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='Class', y='Amount', data=df_cc)\n",
    "plt.title('Transaction Amounts by Fraud Status')\n",
    "plt.xlabel('Is Fraud')\n",
    "plt.ylabel('Amount')\n",
    "plt.ylim(0, 2000) # Limiting for better visualization\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix to see relationships between numerical variables\n",
    "# Due to the large number of PCA components (V1-V28), we'll check correlations with 'Time', 'Amount', and 'Class'\n",
    "plt.figure(figsize=(10,8))\n",
    "correlation_matrix = df_cc[['Time', 'Amount', 'Class']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of Time, Amount, and Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f4771d",
   "metadata": {},
   "source": [
    "## Data Transformation\n",
    "For the credit card dataset, the primary transformation needed is to scale the `Time` and `Amount` columns, as the `V` columns are already scaled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4eca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale 'Time' and 'Amount'\n",
    "scaler = StandardScaler()\n",
    "df_cc['scaled_amount'] = scaler.fit_transform(df_cc['Amount'].values.reshape(-1,1))\n",
    "df_cc['scaled_time'] = scaler.fit_transform(df_cc['Time'].values.reshape(-1,1))\n",
    "\n",
    "# Drop the original columns\n",
    "df_cc.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "df_cc[['scaled_amount', 'scaled_time']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fd192b",
   "metadata": {},
   "source": [
    "## Handle Class Imbalance\n",
    "Just like the fraud dataset, the credit card dataset is highly imbalanced. We will use SMOTE to address this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46f3103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X_cc = df_cc.drop('Class', axis=1)\n",
    "y_cc = df_cc['Class']\n",
    "\n",
    "# Apply SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_cc_resampled, y_cc_resampled = smote.fit_resample(X_cc, y_cc)\n",
    "\n",
    "print(\"Class distribution before SMOTE:\\n\", y_cc.value_counts())\n",
    "print(\"\\nClass distribution after SMOTE:\\n\", pd.Series(y_cc_resampled).value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
